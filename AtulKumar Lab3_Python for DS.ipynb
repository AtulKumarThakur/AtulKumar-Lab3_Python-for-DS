{"cells":[{"cell_type":"markdown","id":"fcbd582c","metadata":{"id":"fcbd582c"},"source":["## Learning Outcomes\n","- Exploratory data analysis & preparing the data for model building. \n","- Machine Learning - Supervised Learning Classification\n","  - Logistic Regression\n","  - Naive bayes Classifier\n","  - KNN Classifier\n","  - Decision Tree Classifier\n","  - Random Forest Classifier\n","  - Ensemble methods\n","- Training and making predictions using different classification models.\n","- Model evaluation"]},{"cell_type":"markdown","id":"f2e961f9","metadata":{"id":"f2e961f9"},"source":["## Objective: \n","- The Classification goal is to predict “heart disease” in a person with regards to different factors given. \n","\n","## Context:\n","- Heart disease is one of the leading causes of death for people of most races in the US. At least 1 of 3 key risk factors for heart disease: high blood pressure, high cholesterol, and smoking. \n","- Detecting and preventing the factors that have the greatest impact on heart disease is very important in healthcare. Machine learning methods may detect \"patterns\" from the data and can predict whether a patient is suffering from any heart disease or not..\n","\n","## Dataset Information\n","\n","#### Source: https://www.kaggle.com/datasets/kamilpytlak/personal-key-indicators-of-heart-disease?datasetId=1936563&sortBy=voteCount\n","Originally, the dataset come from the CDC and is a major part of the Behavioral Risk Factor Surveillance System (BRFSS), which conducts annual telephone surveys to gather data on the health status of U.S. residents. \n","\n","This dataset consists of eighteen columns\n","- HeartDisease: Respondents that have ever reported having coronary heart disease (CHD) or myocardial infarction (MI)\n","- BMI: Body Mass Index (BMI)\n","- Smoking: smoked at least 100 cigarettes in your entire life\n","- AlcoholDrinking: Heavy drinkers (adult men having more than 14 drinks per week and adult women having more than 7 drinks per week\n","- Stroke:Ever had a stroke?\n","- PhysicalHealth: physical health, which includes physical illness and injury\n","- MentalHealth: for how many days during the past 30 days was your mental health not good?\n","- DiffWalking: Do you have serious difficulty walking or climbing stairs?\n","- Sex: male or female?\n","- AgeCategory: Fourteen-level age category\n","- Race: Imputed race/ethnicity value\n","- Diabetic: diabetes?\n","- PhysicalActivity: Adults who reported doing physical activity or exercise during the past 30 days other than their regular job\n","- GenHealth: Would you say that in general your health is good, fine or excellent?\n","- SleepTime: On average, how many hours of sleep do you get in a 24-hour period?\n","- Asthma: you had asthma?\n","- KidneyDisease: Not including kidney stones, bladder infection or incontinence, were you ever told you had kidney disease?\n","- SkinCancer: Ever had skin cancer?"]},{"cell_type":"markdown","id":"f8617014","metadata":{"id":"f8617014"},"source":["### 1. Importing Libraries"]},{"cell_type":"code","execution_count":null,"id":"c7172d3b","metadata":{"id":"c7172d3b"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","import seaborn as sns"]},{"cell_type":"markdown","id":"8fe1a778","metadata":{"id":"8fe1a778"},"source":["### 2. Load the dataset and display a sample of five rows of the data frame."]},{"cell_type":"code","execution_count":7,"id":"70984f5f","metadata":{"id":"70984f5f"},"outputs":[{"ename":"NameError","evalue":"name 'pd' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheart_2020_cleaned.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(data\u001b[38;5;241m.\u001b[39mhead())\n","\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"]}],"source":["data = pd.read_csv(\"heart_2020_cleaned.csv\")\n","print(data.head())"]},{"cell_type":"markdown","id":"eda763be","metadata":{"id":"eda763be"},"source":["### 3. Check the shape of the data (number of rows and columns). Check the general information about the dataframe using the .info() method."]},{"cell_type":"code","execution_count":null,"id":"c246297d","metadata":{"id":"c246297d"},"outputs":[],"source":["print(data.shape)\n","print(data.info())"]},{"cell_type":"markdown","id":"b8470476","metadata":{"id":"b8470476"},"source":["### 4. Check the statistical summary of the dataset and write your inferences."]},{"cell_type":"code","execution_count":null,"id":"b28786f2","metadata":{"id":"b28786f2"},"outputs":[],"source":["descriptive_stats = data.describe(include='all')\n","print(descriptive_stats)\n","print(\"\\nInferences:\")\n","print(\"- Numerical features have minimum, maximum, mean, standard deviation, etc.\")\n","print(\"- Categorical features have counts and frequencies for each category.\")"]},{"cell_type":"markdown","id":"25d21a69","metadata":{"id":"25d21a69"},"source":["### 5. Check the percentage of missing values in each column of the data frame. Drop the missing values if there are any."]},{"cell_type":"code","execution_count":null,"id":"20d33888","metadata":{"id":"20d33888"},"outputs":[],"source":["print(data.isnull().sum()) \n","dropped_data = data.dropna()\n","print(f\"\\nShape of data after dropping rows with missing values: {dropped_data.shape}\")"]},{"cell_type":"markdown","id":"030b4016","metadata":{"id":"030b4016"},"source":["### 6. Check if there are any duplicate rows. If any drop them and check the shape of the dataframe after dropping duplicates."]},{"cell_type":"code","execution_count":null,"id":"11f42ddc","metadata":{"id":"11f42ddc"},"outputs":[],"source":["duplicates = data.duplicated()\n","if duplicates.any():\n","  print(\"Duplicate rows found!\")\n","  dropped_duplicates = data.drop_duplicates()\n","  print(f\"\\nShape of data after dropping duplicates: {dropped_duplicates.shape}\")\n","else:\n","  print(\"No duplicate rows found.\")"]},{"cell_type":"markdown","id":"817d0f41","metadata":{"id":"817d0f41"},"source":["### 7. Check the distribution of the target variable (i.e. 'HeartDisease') and write your observations."]},{"cell_type":"code","execution_count":null,"id":"62d1e2b3","metadata":{"id":"62d1e2b3"},"outputs":[],"source":["heart_disease_counts = data[\"HeartDisease\"].value_counts()\n","print(heart_disease_counts)\n","print(\"\\nObservations:\")\n","print(\"- Number of people with heart disease:\", heart_disease_counts[1])  \n","print(\"- Number of people without heart disease:\", heart_disease_counts[0])  \n","print(\"- The data might be imbalanced if the difference is significant.\")"]},{"cell_type":"markdown","id":"1cd33e88","metadata":{"id":"1cd33e88"},"source":["### 8. Visualize the distribution of the target column 'Heart disease' with respect to various categorical features and write your observations."]},{"cell_type":"code","execution_count":null,"id":"888be5c5","metadata":{"id":"888be5c5"},"outputs":[],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","categorical_features = [\"Smoking\", \"Sex\", \"PhysicalActivity\"]\n","for feature in categorical_features:\n","  plt.figure()\n","  data.groupby(feature)[\"HeartDisease\"].value_counts().unstack().plot(kind=\"bar\", stacked=False)\n","  plt.xlabel(feature)\n","  plt.ylabel(\"Count\")\n","  plt.title(f\"Distribution of Heart Disease by {feature}\")\n","  plt.xticks(rotation=0)  \n","  plt.tight_layout()\n","  plt.show()\n","print(\"Observations:\")\n","print(\"- Visualizations help identify potential relationships between categorical features and heart disease.\")"]},{"cell_type":"markdown","id":"11af76b7","metadata":{"id":"11af76b7"},"source":["### 9. Check the unique categories in the column 'Diabetic'. Replace 'Yes (during pregnancy)' as 'Yes' and 'No, borderline diabetes' as 'No'."]},{"cell_type":"code","execution_count":null,"id":"86fccebe","metadata":{"id":"86fccebe"},"outputs":[],"source":["unique_categories = data['Diabetic'].unique()\n","replace_map = {'Yes (during pregnancy)': 'Yes', 'No, borderline diabetes': 'No'}\n","if any(category in unique_categories for category in replace_map.keys()):\n","  data['Diabetic'] = data['Diabetic'].replace(replace_map)\n","  print(\"Replaced categories in 'Diabetic'\")\n","else:\n","  print(\"No replacements needed for 'Diabetic' categories\")"]},{"cell_type":"markdown","id":"e204cd08","metadata":{"id":"e204cd08"},"source":["### 10. For the target column 'HeartDiease', Replace 'No' as 0 and 'Yes' as 1. "]},{"cell_type":"code","execution_count":null,"id":"22190734","metadata":{"id":"22190734"},"outputs":[],"source":["data['HeartDisease'] = data['HeartDisease'].replace({'No': 0, 'Yes': 1})\n","print(data.head())"]},{"cell_type":"markdown","id":"7cdb58cd","metadata":{"id":"7cdb58cd"},"source":["### 11. Label Encode the columns \"AgeCategory\", \"Race\", and \"GenHealth\". Encode the rest of the columns using dummy encoding approach."]},{"cell_type":"code","execution_count":null,"id":"707747be","metadata":{"id":"707747be"},"outputs":[],"source":["from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n","categorical_features = ['AgeCategory', 'Race', 'GenHealth']\n","numerical_features = [col for col in data.columns if col not in categorical_features]\n","label_encoder = LabelEncoder()\n","for feature in categorical_features:\n","  data[feature] = label_encoder.fit_transform(data[feature])\n","onehot_encoder = OneHotEncoder(sparse=False)  \n","encoded_features = onehot_encoder.fit_transform(data[numerical_features])\n","new_feature_names = onehot_encoder.get_feature_names_out(numerical_features)\n","encoded_df = pd.DataFrame(encoded_features, columns=new_feature_names)\n","data = pd.concat([data[categorical_features], encoded_df], axis=1)\n","print(data.head())"]},{"cell_type":"markdown","id":"ddb3a715","metadata":{"id":"ddb3a715"},"source":["### 12. Store the target column (i.e.'HeartDisease') in the y variable and the rest of the columns in the X variable."]},{"cell_type":"code","execution_count":null,"id":"9628128c","metadata":{"id":"9628128c"},"outputs":[],"source":["y = data['HeartDisease']\n","X = data.drop('HeartDisease', axis=1) \n","print(f\"Shape of X (features): {X.shape}\")\n","print(f\"Shape of y (target): {y.shape}\")"]},{"cell_type":"markdown","id":"68db6b1e","metadata":{"id":"68db6b1e"},"source":["### 13. Split the dataset into two parts (i.e. 70% train and 30% test) and print the shape of the train and test data"]},{"cell_type":"code","execution_count":null,"id":"0077d21b","metadata":{"id":"0077d21b"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) \n","print(f\"Shape of X_train (training features): {X_train.shape}\")\n","print(f\"Shape of X_test (testing features): {X_test.shape}\")\n","print(f\"Shape of y_train (training target): {y_train.shape}\")\n","print(f\"Shape of y_test (testing target): {y_test.shape}\")"]},{"cell_type":"markdown","id":"495ea012","metadata":{"id":"495ea012"},"source":["### 14. Standardize the numerical columns using Standard Scalar approach for both train and test data."]},{"cell_type":"code","execution_count":null,"id":"19357a7b","metadata":{"id":"19357a7b"},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler\n","numerical_features = ['feature1', 'feature2', ...]  \n","scaler = StandardScaler()\n","scaler.fit(X_train[numerical_features])\n","X_train_scaled = scaler.transform(X_train[numerical_features])\n","X_test_scaled = scaler.transform(X_test[numerical_features])\n","X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=numerical_features)\n","X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=numerical_features)\n","print(X_train_scaled_df.head())"]},{"cell_type":"markdown","id":"84d0e4a4","metadata":{"id":"84d0e4a4"},"source":["### 15. Write a function.\n","- i) Which can take the model and data as inputs.\n","- ii) Fits the model with the train data.\n","- iii) Makes predictions on the test set.\n","- iv) Returns the Accuracy Score."]},{"cell_type":"code","execution_count":null,"id":"e02c8c82","metadata":{"id":"e02c8c82"},"outputs":[],"source":["from sklearn.metrics import accuracy_score\n","\n","def fit_predict_evaluate(model, X_train, y_train, X_test, y_test):\n","\"\"\"\n","  Fits a model, makes predictions on a testing set, and returns the accuracy score.\n","\n","  Args:\n","      model: The machine learning model to be trained and evaluated.\n","      X_train: The training features.\n","      y_train: The training target variable.\n","      X_test: The testing features.\n","      y_test: The testing target variable.\n","\n","  Returns:\n","      The accuracy score of the model on the testing set.\n","  \"\"\"\n"," model.fit(X_train, y_train)\n","  y_pred = model.predict(X_test)\n","  accuracy = accuracy_score(y_test, y_pred)\n","  return accuracy\n"]},{"cell_type":"markdown","id":"e709b9d4","metadata":{"id":"e709b9d4"},"source":["### 16. Use the function and train a Logistic regression, KNN, Naive Bayes, Decision tree, Random Forest, Adaboost, GradientBoost, and Stacked Classifier models and make predictions on test data and evaluate the models, compare and write your conclusions and steps to be taken in future in order to improve the accuracy of the model."]},{"cell_type":"code","execution_count":null,"id":"a63e0e03","metadata":{"id":"a63e0e03"},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n","from sklearn.ensemble import StackingClassifier\n","def fit_predict_evaluate(model, X_train, y_train, X_test, y_test):\n","models = [\n","  LogisticRegression(),\n","  KNeighborsClassifier(n_neighbors=5), \n","  GaussianNB(),\n","  DecisionTreeClassifier(),\n","  RandomForestClassifier(n_estimators=100),\n","  AdaBoostClassifier(n_estimators=100),  \n","  GradientBoostingClassifier(n_estimators=100),\n","]\n","for model in models:\n","  model_name = model.__class__.__name__ \n","  accuracy = fit_predict_evaluate(model, X_train_scaled, y_train, X_test_scaled, y_test)\n","  print(f\"{model_name} Accuracy: {accuracy:.4f}\")\n","print(\"\\nConclusions:\")\n","print(\"\\nSteps to improve accuracy:\")\n","from sklearn.model_selection import GridSearchCV\n","param_grid = {\n","  'n_estimators': [50, 100, 200],\n","  'max_depth': [3, 5, 8]\n","}\n","grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5)\n","grid_search.fit(X_train_scaled, y_train)\n","best_forest = grid_search.best_estimator_\n","best_forest_accuracy = fit_predict_evaluate(best_forest, X_train_scaled, y_train, X_test_scaled, y_test)\n","print(f\"\\nBest Random Forest (after tuning) Accuracy: {best_forest_accuracy:.4f}\")"]},{"cell_type":"markdown","id":"K5f-IKPLV3bN","metadata":{"id":"K5f-IKPLV3bN"},"source":["### Conclusion"]},{"cell_type":"code","execution_count":null,"id":"e18c82e0","metadata":{"id":"e18c82e0"},"outputs":[],"source":["The provided code offers a framework for training, evaluating, and comparing various machine learning models for heart disease prediction. By analyzing the accuracy scores of different models, you can gain insights into their effectiveness.\n","\n","Key Takeaways:\n","\n","The code trains and evaluates several classification models (Logistic Regression, KNN, Naive Bayes, Decision Tree, Random Forest, AdaBoost, GradientBoost) on a heart disease dataset.\n","The fit_predict_evaluate function provides a reusable approach to assess model performance.\n","The conclusions section prompts you to analyze the accuracy scores and identify the best performing model. It highlights factors like data quality, feature selection, and hyperparameter tuning that can influence performance."]},{"cell_type":"markdown","id":"515596d0","metadata":{"id":"515596d0"},"source":["----\n","## Happy Learning:)\n","----"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Supervised Learning - Lab Session .ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.0"}},"nbformat":4,"nbformat_minor":5}
